{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8aab378-bbf7-4b44-a0c7-6baeddc74cee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8a98ea5a6140ec936f458a225a5411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "from transformers import AutoModelForCausalLM,BitsAndBytesConfig\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "   llm_int8_skip_modules= [\"resampler\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"AIDC-AI/Ovis1.6-Gemma2-9B\",\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             multimodal_max_length=8192,\n",
    "                                             device_map=\"auto\", \n",
    "                                             quantization_config=nf4_config,\n",
    "                                             trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0df7711-5cc1-49f6-a9ba-4f3a3049083a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pil_image = Image.open(\"temiz.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1298c94c-9019-4cb5-982e-590ad0df422a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_tokenizer = model.get_text_tokenizer()\n",
    "visual_tokenizer = model.get_visual_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a9c25d-30a1-425c-8c89-f87397144644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"bu nedir\"\n",
    "query = f'<image>\\n{prompt}'\n",
    "prompt, input_ids, pixel_values = model.preprocess_inputs(query, [pil_image])\n",
    "attention_mask = torch.ne(input_ids, text_tokenizer.pad_token_id)\n",
    "input_ids = input_ids.unsqueeze(0).to(device=model.device, dtype=torch.bfloat16)  \n",
    "attention_mask = attention_mask.unsqueeze(0).to(device=model.device)\n",
    "pixel_values = pixel_values.unsqueeze(0).to(dtype=torch.bfloat16, device=model.device)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
